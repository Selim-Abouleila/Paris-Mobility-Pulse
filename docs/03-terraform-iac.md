# File: docs/03-terraform-iac.md

# Infrastructure as Code (Terraform)

We use Terraform to capture the state of our GCP infrastructure for reproducibility and portfolio demonstration. Note that we adopt a **hybrid approach**: long-lived infrastructure (BigQuery, Pub/Sub, IAM) is managed by Terraform, while application deployments (Cloud Run services) are managed by `gcloud` to avoid deployment conflicts.

## Directory Layout

```text
infra/terraform/
├── gcloud-export/              # Raw export from GCP (created by bulk-export)
├── gcloud-export-modules.tf    # Module definitions (generated by generate-import)
├── terraform_import_*.sh       # Import script (generated by generate-import)
├── main.tf                     # Manual overrides or main config (if any)
└── versions.tf                 # Provider versions
```

## Prerequisites (Cloud Shell)

1.  **Cloud Shell** is recommended as it has `gcloud` and `terraform` pre-installed.
2.  **Enable Cloud Asset API** (required for export):
    ```bash
    gcloud services enable cloudasset.googleapis.com
    ```
3.  **Install Config Connector CLI** (required for bulk-export resource formatting):
    > **Note**: System packages in Cloud Shell are ephemeral. You may need to run this again if your session resets.
    ```bash
    sudo apt-get install google-cloud-cli-config-connector
    ```

## 1. Export Existing Resources

We assume the infrastructure was created manually (via `gcloud` or Console). We export it to Terraform to establish a baseline.

From the repository root (`~/Paris-Mobility-Pulse`):

1.  Create the export directory:
    ```bash
    mkdir -p infra/terraform/gcloud-export
    ```

2.  Run the bulk export:
    ```bash
    gcloud beta resource-config bulk-export \
      --path=infra/terraform/gcloud-export \
      --project=paris-mobility-pulse \
      --resource-format=terraform
    ```
    *This will create multiple subdirectories in `gcloud-export` organized by project definition and resource kind.*

## 2. Generate Modules & Import Script

Now we generate the Terraform configuration wrapper and the shell script to import state.

1.  Navigate to the terraform directory:
    ```bash
    cd infra/terraform
    ```

2.  Generate the import helper (pointing to the export directory we just filled):
    ```bash
    gcloud beta resource-config terraform generate-import gcloud-export
    ```
    *This creates `gcloud-export-modules.tf` and a script named like `terraform_import_20250121-100000.sh`.*

## 3. Init, Import, and Plan

1.  Initialize Terraform:
    ```bash
    terraform init
    ```

2.  Run the generated import script (use wildcard as timestamp varies):
    ```bash
    chmod +x terraform_import_*.sh
    ./terraform_import_*.sh
    ```
    *This imports the real GCP resources into your local `terraform.tfstate`.*

3.  Check the plan:
    ```bash
    terraform plan
    ```

## 4. Exclude Cloud Run (Terraform-managed vs Manual)

**Decision**: We do **NOT** manage Cloud Run services with Terraform primarily to avoid drift when we deploy new revisions via `gcloud run deploy`.

### Action Required
If `terraform plan` shows changes to Cloud Run services (destroy/recreate or modify), you must remove them from Terraform management.

1.  Open `gcloud-export-modules.tf`.
2.  Find and **delete/comment out** the module blocks related to Cloud Run (e.g., `module "run_service_..."`).
3.  Remove them from the state file if they were already imported:
    ```bash
    # List them to find the address
    terraform state list | grep run

    # Remove from state (example)
    terraform state rm module.gcloud-export-modules.google_cloud_run_service.pmp_velib_collector
    terraform state rm module.gcloud-export-modules.google_cloud_run_service.pmp_bq_writer
    ```

After exclusion, `terraform plan` should show minimal changes (e.g., label updates).

## 5. Apply & Troubleshooting

Once expectations match (e.g., "Plan: 0 to add, 5 to change"), apply the state consistency updates:

```bash
terraform apply
```

### Auth Troubleshooting
If you see errors like:
`oauth2/google: invalid token JSON from metadata: EOF`
It means Cloud Shell's default credential helper is struggling. Use Application Default Credentials (ADC):

```bash
# Login with ADC
gcloud auth application-default login --no-launch-browser

# Set quota project to ours
gcloud auth application-default set-quota-project paris-mobility-pulse

# Point Terraform to the credentials
export GOOGLE_APPLICATION_CREDENTIALS="$HOME/.config/gcloud/application_default_credentials.json"
```
*Retry `terraform plan` after running these commands.*

## 6. Git Hygiene

**Commit these:**
- `infra/terraform/gcloud-export/**` (The resource definitions)
- `infra/terraform/gcloud-export-modules.tf` (The module registry)
- `.terraform.lock.hcl`

**Do NOT Commit:**
- `terraform.tfstate` & `terraform.tfstate.backup` (Contains sensitive data)
- `.terraform/` (Plugins)
- `*.tfvars`

### Recommended .gitignore extension
```gitignore
# Terraform
.terraform/
*.tfstate
*.tfstate.backup
*.tfvars
```

## Management Stategy

| Resource Type | Managed By | Notes |
| :--- | :--- | :--- |
| **BigQuery** | Terraform | Dataset `pmp_raw`, Table schemas. |
| **Pub/Sub** | Terraform | Topics and Subscriptions. |
| **IAM** | Terraform | Service Account bindings. |
| **Cloud Run** | **gcloud** | Excluded from TF to allow imperative deploys. |
